          FACE DETECTION + TAG YOUR FRIENDS

Source: https://www.youtube.com/watch?v=wVK3HHbli7g&t=32s

En este proyecto vamos a usar una API que usara AI para detectar rostros en una imagen.La API se llama face-api.js
Puedo ver su web aqui:
https://justadudewhohacks.github.io/face-api.js/docs/index.html

Para instalarla basta con:
npm i face-api.js

Para usarla hay que configurar algunas cosas.Dentro de la carpeta public de mi app de react hay que pegar los modelos
que están en este repo en el folder 'weights':
https://github.com/justadudewhohacks/face-api.js/

Voy a usar la API Canvas que me va a permitir dibujar en la imagen.Recuerda que hay que dar un alto,un ancho y un id a la etiqueta:
<canvas id="myCanvas" width="400px" height="300px" style="border:1px solid black"/>

Despues recupero el contexto y ya puedo pintar en el lienzo:
const ctx = document.getElementById("myCanvas").getContext("2d")
ctx.strokeRect(50,50,100,100)

Dado que estamos en React usaré una ref.Además necesito varias:

const imgRef = useRef();
const canvasRef = useRef();

      <img
        ref={imgRef}
        width="940"
        height="650" />

      <canvas
        ref={canvasRef}
        width="940"
        height="650" />

Para cargar un modelo(no vamos a usar todos) en un entorno NOde hay que usar:
await faceapi.nets.${modelName}.loadFromDisk('./models')
* también se puede usar loadFromURI

impor * as faceapi from 'face-api.js' <- lo pide asi parece

Vamos a cargar todos los modelos en un efecto,pero no pueden empezar a cargarse si no hay una imagen.Ademas los vamos a cargar en paralelo:

useEffect(() => {
    const loadModels = () => {
      Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('/models'),  
      faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
      faceapi.nets.faceExpressionNet.loadFromUri('/models')
      ])
        .then(console.log('Models loaded'))
        .then(handleImage)
        .catch(err => console.log(err));
    }
    imgRef && loadModels();
  },[])

Para usar estos modelos en vez de ese console log vamos a usar una funcion para procesar esa imagen.
  const handleImage = async () => {
    const detections = await faceapi.detectAllFaces(
      imgRef.current,
      new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceExpressions()

      console.log(detections);
  };
NOTA:escanear el nuevo DNI para el banco.

Puedo ver que esa petición me devuelve un object con muchos datos,pero entre ellos tendré a detections.box.con el _width y _height.

alignedRect: 
detection: FaceDetection
_box: Box {_x: 418.03876016313285, _y: 554.1584360110411, _width: 361.75962553908664, _height: 333.64745375235856}
_className: ""
_classScore: 0.8214654270312282
_imageDims: Dimensions {_width: 1000, _height: 1500}
_score: 0.8214654270312282
box: Box
_height: 333.64745375235856
_width: 361.75962553908664
_x: 418.03876016313285
_y: 554.1584360110411

NOTA: podríamos usar el canvas para pintar un recuadro pero la propia API ya trae esa funcionalidad.

// la propia libreria ya interactua con la API canvas 
// 1º hay que crear un Canvas
canvasRef.current.innerHtml = faceapi.createCanvasFromMedia(imgRef.current);

// 2º doy unas dimensiones a ese canvas
 faceapi.matchDimensions(canvasRef.current, {width: imgRef.current.width, height: imgRef.current.height});
// también debo redimensionar los cuadrados resultantes
const resized  = faceapi.resizeResults(detections, {width: imgRef.current.width, height: imgRef.current.height});

// 3º dibujo las detecciones que esté buscando;
faceapi.draw.drawDetections(canvasRef.current, resized);

EJEMPLO REAL: es obvio que esto no sirve para mucho.Hagamos algo para poder etiquetar los amigos en una foto.
Creo un input type file del estilo que quiera.Lo que haremos será no subir la imagen al backend,crearemos una fake url.

Esto es algo que ya he hecho antes con el método estático URL.createObjectURL(file) que crea una fake url:
  useEffect(() => {
    if(file){
       console.log(URL.createObjectURL(file));
    }
  },[file]);
NOTA: la fake url que crea el método es asi:
blob:http://localhost:3000/d5800a86-1905-40f5-86e4-7c4a77a5bb9a
Parece volátil y se ve que no es real.Pero valdrá para hacer algo momentáneamente.

Fijate que este efecto se dispara cada vez que haya un file,es decir,cada vez que un usuario seleccione una imagen en el navegador del filesystem.

Sin embargo necesito saber la altura y ancho de la imagen de esa imagen para el canvas,recuerda.

Para esto voy a necesitar dos estados,uno para el file y otro para esta fakeURl:

const [ file,setFile ] = useState();
 const [ image,setImage ] = useState();
  
useEffect(() => {
  const getImage = () => {
    const img = new Image();
    img.src = URL.createObjectURL(file);
    img.onload = () => {
      setImage({
        url: img.src,
        width: img.width,
        height: img.height
      });
    }}
    file && getImage();    
  },[file]);
*Fijate que el efecto se dispara cuando haya un file y que crea una url falsa y la guarda en el estado image.
Despues llamamos a un componente condicionalmente

  { image ? (
        <NewPost image={image} />
      ) : (
Este NewPost es el que carga los modelos.
Aqui cargaré las caras y crearé inputs para cada una,etc...
 const { url, width, height } = image;
  const [ faces,setFaces ] = useState([]);
  const [friends,setFriends] = useState([]);

const createTags = async () => {
    // detections va a ser un array con todas las caras detectadas(si hay una solo tendrá un elemento)
      const detections = await faceapi.detectAllFaces(
        imgRef.current,
        new faceapi.TinyFaceDetectorOptions())
        //en box tengo las 4 coordenadas que necesita el canvas
    setFaces(detections.map( d => Object.values(d.box)));
  }

  const enter = () => {
    const ctx = canvasRef.current.getContext('2d');
    ctx.lineWidth =5;
    ctx.strokeStyle = 'red';
    faces.map(face => ctx.strokeRect(...face))
  }

  const addFriend =  (e) => {
    e.preventDefault();
    setFriends( prev => ({
      ...prev,
      [e.target.name]: e.target.value
    }));
  }

  En el mouseEnter creo un cuadrado por face y le creo un input.EL contenido de estos inputs los meto en setFriends.
   <canvas 
          onMouseEnter={enter}
          ref={canvasRef} 
          width={width} 
          height={height}
            />
            {faces.map( (face,i) =>(
              <input 
                name={`input${i}`}
                style={{ 
                  position: 'absolute',
                  top: face[1]+face[3]+5,
                  left: face[0] }}
                placeholder="Tag a friend" 
                key={i}
                className="friendInput"
                onChange={addFriend}
              />
            ))}
      </div>
      <div className="right">
        <h1>Share your post</h1>
        <input type="text" placeholder="What's on your mind"
        className="rightInput" />
    
        { friends && (
          <span className="friends">With 
            <span className="name">
            {Object.values(friends)+" "}
            </span>
          </span>
        )}
        <button className="rightButton">Send</button>

No entiendo muy bien que podría guardar tras etiquetar a una persona.¿Simplemente su nombre?Desde luego el cuadro,no.Puedo guardar las posiciones y el userId para despues al hacer hover que salga el nombre.Parece una buena opción.